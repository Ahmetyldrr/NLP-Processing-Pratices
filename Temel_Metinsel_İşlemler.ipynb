{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MjpLlNs4SvyO",
        "dGO45bD1RHR6",
        "wg2YUe5eShP-",
        "fTflybFtHa-i"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNpxe/FXzWOyD9q2oaUBgpz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmetyldrr/NLP-Processing-Pratices/blob/main/Temel_Metinsel_%C4%B0%C5%9Flemler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bölüm 1: NLP'ye Giriş**"
      ],
      "metadata": {
        "id": "MjpLlNs4SvyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Heyecan verici Doğal Dil İşleme (NLP) dünyasına hoş geldiniz. Bu bölüm, NLP'nin temel kavramlarını ve temel unsurlarını anlamak için bir geçit görevi görür. Bu yolculuğa çıkarken, NLP'nin ne olduğunu, neden önemli olduğunu ve çeşitli alanlarda nasıl uygulandığını keşfedeceğiz. Bu bölümün sonunda, NLP'nin temel prensipleri hakkında sağlam bir anlayışa sahip olacak ve daha teknik yönlere derinlemesine dalmaya hazır olacaksınız.\n",
        "NLP, dilbilim, bilgisayar bilimi ve yapay zekayı harmanlayan büyüleyici bir alandır. Makinelerin insan dilini değerli bir şekilde yorumlamasını, anlamasını ve yanıtlamasını sağlar. Günümüzün veri odaklı dünyasında NLP, arama motorlarından ve çeviri hizmetlerinden sohbet robotlarına ve duygu analizi araçlarına kadar birçok uygulamanın kritik bir bileşeni haline gelmiştir.\n",
        "Bu bölüm temel bir soruyla başlıyor: Doğal Dil İşleme Nedir? NLP'nin tanımını, kapsamını ve uygulamalarını inceleyerek, takip edecek daha detaylı tartışmalar için sahneyi hazırlayan kapsamlı bir genel bakış sunacağız."
      ],
      "metadata": {
        "id": "Xp70bITzSs53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bölüm 2: Temel Metin İşlemleri**\n"
      ],
      "metadata": {
        "id": "dGO45bD1RHR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.1 Metin Verilerini Anlamak**"
      ],
      "metadata": {
        "id": "wg2YUe5eShP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metin verileri doğası gereği yapılandırılmamıştır ve makaleler, sosyal medya gönderileri, e-postalar, sohbet mesajları, incelemeler ve daha fazlası gibi çeşitli biçimlerde olabilir. Yapılandırılmış yapısı nedeniyle makineler tarafından kolayca analiz edilebilen sayısal verilerin aksine, metin verileri yapılandırılmış bir biçime dönüştürmek için özel işleme ve işleme teknikleri gerektirir.\n",
        "Bu dönüşüm, algoritmaların metinde yer alan bilgileri verimli bir şekilde işleyebilmesi ve anlayabilmesi için olmazsa olmazdır. Nüansları, deyimleri ve çeşitli sözdizimleriyle insan dilinin karmaşıklığı, bu göreve ek bir zorluk katmanı ekler.\n",
        "Bu nedenle, metin verilerinden anlam çıkarmak ve anlamlı çıkarımlar yapmak için doğal dil işleme (NLP), makine öğrenmesi teknikleri ve çeşitli metin madenciliği stratejileri gibi gelişmiş yöntemler kullanılmaktadır.\n",
        "Bu yöntemler, mevcut metinsel bilgilere dayanarak eğilimleri kategorize etmeye, özetlemeye ve hatta tahmin etmeye yardımcı olur."
      ],
      "metadata": {
        "id": "cyYLV8JASYUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.2 Metin Temizleme: Durdurma Sözcüğü Kaldırma, Köklendirme, Lemmatizasyon**"
      ],
      "metadata": {
        "id": "nQSOcClvSQzt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metinlerin içinde bir çok karakter noktalama ve farklı durumlar vardır. Veri ön işleme aşamalarında temizleme yapılması gerekmektedir.\n",
        "Metin verilerinden anlam çıkarmak ve anlamlı içgörüler çıkarmak için kullanılır. Bu yöntemler, mevcut metinsel bilgilere dayanarak eğilimleri kategorize etmeye, özetlemeye ve tahmin etmeye yardımcı olur.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mpw55RgjRPYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metin verilerinin ön işlenmesi, herhangi bir Doğal Dil İşleme (NLP) kanalında kritik bir adımdır. Uygun ön işleme, metnin temiz, tutarlı ve makine öğrenimi modelleri tarafından kolayca analiz edilebilecek bir formatta olmasını sağlar. Bu adım, ham metin verilerini daha fazla analiz için hazırlamak üzere çeşitli teknikler ve yöntemler içerir. Metnin ön işlenmesinin temel nedenleri şunlardır"
      ],
      "metadata": {
        "id": "XYWkBEEzSW5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gürültü Azaltma**"
      ],
      "metadata": {
        "id": "yXc0BZcTSfJw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 - Noktalama İşaretlerinin Kaldırılması"
      ],
      "metadata": {
        "id": "LFLRiojPSisA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 - Durdurma Sözcüklerinin Kaldırılması ( the , is , in, and )"
      ],
      "metadata": {
        "id": "tfuZ5hSZSm65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FeKcMreQWPaZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 - Özel Öğrelerin Kaldırılması ( HTML , kodlar vs )"
      ],
      "metadata": {
        "id": "ZWyc-6ArSvfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example, when text data is free from unnecessary noise, tokenization, stemming, and lemmatization processes become more efficient and accurate <br>\n",
        "Text gereksiz gürültüden kurtulduğunda işlemlerin doğruluk payı artmaktadır\n"
      ],
      "metadata": {
        "id": "bwKl5Oq9S-5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Standartizasyon**"
      ],
      "metadata": {
        "id": "5cagsh8yTTRS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 - Küçük harf"
      ],
      "metadata": {
        "id": "RsIOsPpbWLHi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 - Köklendirme\n",
        "\n",
        "Mesela running kelimesini run olarak almak\n",
        "\n"
      ],
      "metadata": {
        "id": "sGZehL5pWNSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 - Lemmatizasyon\n",
        "\n",
        "Mesela \"daha iyi\" kelimesini \"iyi\" şeklinde alınmasıdır."
      ],
      "metadata": {
        "id": "UtcmBFA_WP-_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Özellik Çıkarımı**"
      ],
      "metadata": {
        "id": "WT3-PocSWpxb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ham metni özelliklere çıkarmak makine öğrenmesi açısından en önemli parçalardan bir tanesidir.\n",
        "Bu kalıpların çıkarılması metin verilerine dayalı sınıflandırmalar veya tahminler için kullanılır."
      ],
      "metadata": {
        "id": "d2ZQH5DEWtwX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 - Tokenleştirme\n",
        "\n",
        "Verileri daha küçük parçalar halinde gösterme işlemidir."
      ],
      "metadata": {
        "id": "aqt1KrMVZ3Ak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 - Vektörleştirme\n",
        "\n",
        "Verileri makinenin anlayabileceği sayısal verilere dönüştürme işlemidir.\n",
        "\n",
        " Techniques such as Bag of Words (BoW), Term Frequency-Inverse Document Frequency (TF-IDF), and Word2Vec are commonly employed for this conversion.\n",
        "\n",
        " Bu dönüşüm için genellikle Kelime Torbası (BoW), Terim Frekansı-Ters Belge Frekansı (TF-IDF) ve Word2Vec gibi teknikler kullanılır. Bu sayısal gösterimler kritik öneme sahiptir çünkü makine öğrenimi algoritmalarının metin verileri üzerinde karmaşık matematiksel işlemler gerçekleştirmesini sağlayarak daha derin analiz ve içgörüler sağlar."
      ],
      "metadata": {
        "id": "F9qNVGmCaGi5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 - Embedding\n",
        "\n",
        "Bu işlem kelimeleri ya da cümleleri daha yüksek boyutlu vektörlere eşlendiği durumu ifade eder.\n",
        "\n",
        "Word2Vec, GloVe ve BERT gibi popüler yöntemler bu gömmeleri oluşturmak için sıklıkla kullanılır.\n",
        "\n"
      ],
      "metadata": {
        "id": "6-Ld1rC7ab4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ham metni bu özelliklere dönüştürerek, makine öğrenimi modelleri verileri daha iyi anlayabilir ve yorumlayabilir. Bu işlem sırasında çıkarılan özellikler, algoritmaların metinden öğrenmesi için gerekli girdiyi sağlar ve bu sayede kalıpları tanımalarını, doğru tahminlerde bulunmalarını ve duygu analizi, metin sınıflandırması ve dil çevirisi gibi çeşitli NLP görevlerini gerçekleştirmelerini sağlar."
      ],
      "metadata": {
        "id": "aQCOXVv8bBRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ham Metin Verilerini Keşfetme**"
      ],
      "metadata": {
        "id": "xvE9vNZubJQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Natural Language Processing (NLP) enables computers to understand human language.\""
      ],
      "metadata": {
        "id": "RMGeh9R7bPHk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\\\\\\\nLength of the text:\", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU6M3xG9bRHQ",
        "outputId": "68597881-b478-4a3c-abe7-bdcd6a636a46"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\\\nLength of the text: 81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_characters = set(text)\n",
        "print(\"\\\\\\\\nUnique characters:\", unique_characters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZgpaWn9bUWi",
        "outputId": "4561beb6-00c5-4f53-bc7b-3ba1aa822688"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\\\nUnique characters: {'u', 'P', 'd', ' ', 'h', 'L', 'm', 's', 't', 'o', 'b', 'r', 'p', '(', 'N', 'i', 'n', '.', 'e', 'a', 'l', ')', 'c', 'g'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = text.split()\n",
        "print(\"\\\\\\\\nNumber of words:\", len(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4alcS9fbaWY",
        "outputId": "7217f3a5-3746-4df0-a7f8-5a791d4c9b8e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\\\nNumber of words: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Metin Verileri ile ilgili Zorluklar**"
      ],
      "metadata": {
        "id": "UCb5HJiXbhoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 - Belirsizlik - Ambiguity\n",
        "\n",
        "Bazı kelimeler birden fazla anlama sahip olabilir.Dilin bu özelliği algoritmalar için anlam sorunu oluşturabilir.Bu nedenle bağlamsal bilgi olmadan algoritma bunu yanlış değerlendirebilir.\n"
      ],
      "metadata": {
        "id": "WDpZmx-gbmtx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 - Değişkenlik -  Variability\n"
      ],
      "metadata": {
        "id": "xC7a7U7XcHnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bazen sosyal medya gönderimleri kısaltma ,argo vb özellikte olabilir.\n",
        "\n",
        "Ek olarak, metnin yazıldığı bağlam, yapısını ve anlamını etkileyebilir. Örneğin, \"bankayı kırmak\" gibi bir ifade, finansal bir bağlamda aşırı harcama anlamına gelebilir, ancak farklı bir bağlamda, bir bankaya girmenin fiziksel bir eylemini ifade edebilir. Bu bağlamsal nüansları anlamak, doğru metin analizi için esastır."
      ],
      "metadata": {
        "id": "0gFmYjHXcMBT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 - Gürültülü Veri - Noisy Data"
      ],
      "metadata": {
        "id": "BQdvHih3cu9x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "İnternetten aldığımız veriler örnek olarak HTML gibi etiketler içeriyor olabilir.\n",
        "\n",
        "Düzgün bir şekilde temizlenip filtrelenmezlerse, gürültülü veriler NLP modellerinin performansını önemli ölçüde engelleyebilir\n",
        "\n",
        "İlgisiz bilgilerin varlığı, modellerin sahte desenler ve korelasyonlar öğrenmesine yol açabilir ve böylece etkinliklerini ve doğruluklarını azaltabilir."
      ],
      "metadata": {
        "id": "rkKAO3FUc5eg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4 - Yüksek Boyutluluk -  High Dimensionality\n",
        "\n",
        "Yüksek boyut hesaplama karmaşıklığına neden olabilir.Aşırı uyum ve başka zorluklara neden olabilir.\n",
        "\n",
        "a - Hesaplama Karmaşıklığı - Computational Complexity\n",
        "\n",
        "b - Aşırı Uyum - Overfitting\n",
        "\n",
        "c - Boyutluluk Laneti - Curse of Dimensionality\n",
        "\n",
        "boyut sayısı arttıkça veri noktalarının seyrek hale gelmesidir. Bu seyreklik, algoritmaların verilerde anlamlı örüntüler ve ilişkiler bulmasını zorlaştırır. Ek olarak, veri noktaları arasındaki mesafe daha az bilgilendirici hale gelir ve kümeleme ve en yakın komşu araması gibi görevleri karmaşık hale getirir.\n",
        "\n",
        "d - Özellik Seçimi ve Mühendisliği - Feature Selection and Engineering\n",
        "\n",
        "Terim Frekansı-Ters Belge Frekansı (TF-IDF), Temel Bileşen Analizi (PCA) ve Word2Vec ve BERT gibi çeşitli yerleştirme yöntemleri gibi teknikler, boyutluluğu azaltmaya ve makine öğrenimi modellerinin performansını iyileştirmeye yardımcı olabilir.\n",
        "\n",
        "e -  Depolama ve Ölçeklenebilirlik - Storage and Scalability\n",
        "\n",
        "Yüksek boyutlu verileri depolamak ve yönetmek, özellikle büyük ölçekli metin korpuslarıyla uğraşırken zorlu olabilir\n",
        "\n",
        "Bununla başa çıkmak için bazı işlemler yapılabilir.\n",
        "\n",
        "a - Boyut Azaltma - Dimensionality Reduction\n",
        "\n",
        "Methods such as PCA, Singular Value Decomposition (SVD), and t-Distributed Stochastic Neighbor Embedding (t-SNE) can reduce the number of dimensions while preserving the most important information.\n",
        "\n",
        "PCA , SVD ve t-SNE gibi yöntemler kullanılabilir.\n",
        "\n",
        "b - Düzenleme -  Regularization\n",
        "\n",
        "L1 ve L2 düzenlemesi gibi teknikler, modeldeki büyük katsayılar için ceza ekleyerek aşırı uyumu önlemeye yardımcı olabilir.\n",
        "\n",
        "c - Gelişmiş Gömmeler - Advanced Embeddings\n",
        "\n",
        "Word2Vec, GloVe ve BERT gibi gelişmiş kelime gömme tekniklerini kullanmak, kelimeler arasındaki anlamsal ilişkileri yakalayabilir ve özellik alanının boyutluluğunu azaltabilir.\n",
        "\n",
        " **Duygu ve Öznellik - Sentiment and Subjectivity**\n",
        "\n",
        " Metinler genellikle duygular içerir. bu anlamda metnin pozitif mi , negatif mi , nötr mü olduğunu belirlemek önemlidir. Bazen kelimenin temel anlamı olumsuz olmasına rağmen temelde olumlu bir cümle yaratabilir. Mesela \"fena değil\"\n",
        "\n",
        " Alaycılık ve ironi genellikle ton, bağlam ve paylaşılan kültürel bilgiye dayanır.\n",
        "\n",
        " Bu zorlukların üstesinden gelmek için gelişmiş NLP teknikleri ve modelleri kullanılır. Belirteçleştirme, durdurma sözcüğü kaldırma, köklendirme ve lemmatizasyon gibi teknikler, metni ön işleme tabi tutmaya ve standartlaştırmaya yardımcı olarak analiz etmeyi kolaylaştırır. BERT ve GPT-3 gibi gelişmiş modeller, kelimeler arasındaki bağlamı ve bağımlılıkları anlamak ve duygu analizinin doğruluğunu artırmak için tasarlanmıştır.\n",
        "Metindeki duygu ve öznelliğin analizi, insan dilinin nüanslı ve çeşitli doğası nedeniyle karmaşık bir görevdir. Altta yatan duyguları doğru bir şekilde yakalamak için etkili ön işleme ve gelişmiş modelleme esastır.\n",
        "\n",
        "\n",
        " **Bağlam ve Bağımlılık -  Context and Dependency**\n",
        "\n",
        " Bir metnin anlamını anlamak genellikle bağlamı ve kelimeler arasındaki bağımlılıkları dikkate almayı gerektirir. Örneğin, \"fena değil\" ifadesini ele alalım. İlk bakışta, \"kötü\" kelimesi olumsuz bir duyguyu çağrıştırır. Ancak, \"değil\" ile eşleştirildiğinde, ifade aslında olumlu bir duyguyu iletir ve bir şeyin tatmin edici veya hatta iyi olduğunu gösterir. Bu örnek, tek tek kelimelerin bağlamlarına bağlı olarak nasıl farklı anlamlar taşıyabileceğini göstermektedir."
      ],
      "metadata": {
        "id": "-tSNEmoWiLed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu bağımlılıkları ve bağlamı yakalamak, doğru metin analizi için olmazsa olmazdır. Doğal dil işlemede (NLP), bu yalnızca kelimelerin kendilerini değil, bir cümle veya daha büyük bir metin gövdesi içinde birbirleriyle nasıl ilişkilendiklerini anlamak anlamına gelir."
      ],
      "metadata": {
        "id": "EVGu_WtX8jF_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dil Çeşitliliği - Language Diversity**"
      ],
      "metadata": {
        "id": "xcXRkPFZ8ntV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dil çeşitliliği, her biri kendine özgü dil bilgisi kuralları, kelime bilgisi ve yazı sistemlerine sahip, dünya çapında çok sayıda dil ve lehçenin varlığına işaret eder. Bu çeşitlilik, Doğal Dil İşleme (NLP) alanında önemli bir zorluk teşkil eder. Odak noktasının tek bir dil olduğu tek dilli bir yaklaşımın aksine, birden fazla dili veya lehçeyi etkili bir şekilde işleyebilen NLP modelleri geliştirmek önemli miktarda çaba ve kaynak gerektirir."
      ],
      "metadata": {
        "id": "_w7Q9hrR8yMO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Alaycılık ve İroni - Sarcasm and Irony**"
      ],
      "metadata": {
        "id": "bvOLJ7279Aq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metindeki alaycılığı ve ironiyi tespit etmek bir diğer önemli zorluktur. Bu ifade biçimleri genellikle algoritmaların doğru bir şekilde yorumlamasının zor olduğu ton, bağlam ve kültürel bilgiye dayanır."
      ],
      "metadata": {
        "id": "PKqv1ZYZ9JU0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Temel Metin Ön İşleme Adımları**"
      ],
      "metadata": {
        "id": "3L6Kw5pT9Nb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Natural Language Processing (NLP) enables computers to understand human language.\""
      ],
      "metadata": {
        "id": "LAJNufhYDbTq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text.lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QhsBuP9XDipS",
        "outputId": "e31e2f4f-e768-4c09-fe85-515ec7461e63"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'natural language processing (nlp) enables computers to understand human language.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "text1 = text.translate(str.maketrans('', '', string.punctuation))\n",
        "text1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "UbzsBd9uDlZN",
        "outputId": "c7bbc0f0-7a74-4b93-ffb9-e528ae2989f8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Natural Language Processing NLP enables computers to understand human language'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ49CuVbDu9R",
        "outputId": "c7002e5d-f2e7-47f7-c3ab-fee5bf3a9c57"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'NLP',\n",
              " 'enables',\n",
              " 'computers',\n",
              " 'to',\n",
              " 'understand',\n",
              " 'human',\n",
              " 'language']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2.1 Stop Word Removal - Durdurma Sözcüğünün Kaldırılması**"
      ],
      "metadata": {
        "id": "_ZWZ4TQHD7Cr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Durdurma sözcüklerinin kaldırılması  \"the\", \"is\", \"in\", \"and\" vb."
      ],
      "metadata": {
        "id": "t9uIKcv7EBGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_Wpor73EOZV",
        "outputId": "86985cbe-4690-4b31-901e-51b8e5067cd8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Natural Language Processing enables computers to understand human language.\""
      ],
      "metadata": {
        "id": "pPnBICm3Eb_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = text.split()\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzmBm7EMEdni",
        "outputId": "7cf063ec-7840-4724-fff2-3d1ab0d8fed3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " '(NLP)',\n",
              " 'enables',\n",
              " 'computers',\n",
              " 'to',\n",
              " 'understand',\n",
              " 'human',\n",
              " 'language.']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "filtered_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mS9WytSEhKv",
        "outputId": "b1ea63b3-caa7-4552-d745-d52f09662c5b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " '(NLP)',\n",
              " 'enables',\n",
              " 'computers',\n",
              " 'understand',\n",
              " 'human',\n",
              " 'language.']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Burada \"to\" ifadesi atıldı."
      ],
      "metadata": {
        "id": "kZhcjD6jE2v9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2.2 Köklendirme - Stemming**"
      ],
      "metadata": {
        "id": "Fmiz4ju9E9Qd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Köklendirme Nasıl Çalışır\n",
        "\n",
        "Köklendirme, kelimelerden ekleri, önekleri veya diğer ekleri kaldırarak elde edilir. En yaygın kullanılan köklendirme algoritması, Martin Porter tarafından 1980'de geliştirilen Porter Stemmer'dır. Bu algoritma, kelimeleri köklerine dönüştürmek için bir dizi kural uygular."
      ],
      "metadata": {
        "id": "Xx6atg6jFD4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "text = \"Natural Language Processing enables computers to understand human language.\"\n",
        "tokens = text.split()\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSRqqUaiFIGE",
        "outputId": "6153712a-1492-4828-9d38-628112f236cc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'enables',\n",
              " 'computers',\n",
              " 'to',\n",
              " 'understand',\n",
              " 'human',\n",
              " 'language.']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "E8fkCgLxFRsn"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
        "stemmed_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiLoP18RFUHU",
        "outputId": "8a044a11-3a3d-4fd2-a0f7-a99347350918"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['natur',\n",
              " 'languag',\n",
              " 'process',\n",
              " 'enabl',\n",
              " 'comput',\n",
              " 'to',\n",
              " 'understand',\n",
              " 'human',\n",
              " 'language.']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "bu işlemler diğer dillerde kullanımı uygun olmayabişlir ayrıca köklendirme işlemi çok agresif olduğunda bu soruna neden olabilir. Türk.e için bu konuda çok fazla ek vs olmasından kaynaklı bu tekniğin kullanılması sorunlara neden olur.Bu konuda yeni yöntemler vs denenmesi gerekmektedir."
      ],
      "metadata": {
        "id": "FzrX5YQHF4Rk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2.3 Lemmatizasyon - Lemmatizasyon**"
      ],
      "metadata": {
        "id": "ZoR8hVf5GKAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatizasyon, doğal dil işlemede (NLP) sözcükleri lemma olarak bilinen temel veya kök biçimlerine dönüştüren önemli bir tekniktir. Genellikle önekleri veya sonekleri kesen köklendirmenin aksine, lemmatizasyon daha karmaşıktır ve bağlamı ve sözcük türünü dikkate alarak sözcükleri sözlük biçimlerine indirgemeyi içerir. Bu, lemmatizasyonu çeşitli NLP görevleri için daha doğru ve anlamlı hale getirir."
      ],
      "metadata": {
        "id": "SgVhUFRuGVb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatizasyon Nasıl Çalışır\n",
        "\n",
        "Lemmatizasyon, kelimelerin temel biçimini döndürmek için bir sözlük ve morfolojik analiz kullanmayı içerir. İşlem genellikle doğru olması için kelimenin sözcük türünün bilinmesini gerektirir. Örneğin, \"saw\" kelimesi bir isim veya fiil olabilir ve lemmatizasyon bu kullanımlar arasında ayrım yapabilir."
      ],
      "metadata": {
        "id": "ykV9xL2DGakP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "yYgbHFPCGeWU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1yBCyi2GhRk",
        "outputId": "008a7bee-55be-43b2-a2f6-94a35f880e19"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Natural Language Processing enables computers to understand human language.\""
      ],
      "metadata": {
        "id": "SBQrVEu0Gi5-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = text.split()"
      ],
      "metadata": {
        "id": "LuMAGjuPGkOX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "WTktcW6gGl4L"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "lemmatized_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtSjwDTDGnXu",
        "outputId": "a1ff67ef-5c83-4da1-c4bc-4cf92a6f7dee"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'enables',\n",
              " 'computer',\n",
              " 'to',\n",
              " 'understand',\n",
              " 'human',\n",
              " 'language.']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original Tokens:\")\n",
        "print(tokens)\n",
        "print(\"\\\\\\\\nLemmatized Tokens:\")\n",
        "print(lemmatized_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSo56QqBGx1p",
        "outputId": "8faedae1-b592-4b31-e926-ace3bfe69cd3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tokens:\n",
            "['Natural', 'Language', 'Processing', 'enables', 'computers', 'to', 'understand', 'human', 'language.']\n",
            "\\\\nLemmatized Tokens:\n",
            "['Natural', 'Language', 'Processing', 'enables', 'computer', 'to', 'understand', 'human', 'language.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.3 Regular Expressions**"
      ],
      "metadata": {
        "id": "fTflybFtHa-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3.1 Basics of Regular Expressions**"
      ],
      "metadata": {
        "id": "CGq8dFQmHj8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Genellikle regex olarak kısaltılan düzenli ifade, metin içindeki karakter dizilerini eşleştirmek için kullanılan bir arama modelini tanımlayan bir karakter dizisidir. Bu güçlü araç, metnin bölümlerini bulmak, çıkarmak veya değiştirmek için kullanılabilen belirli modeller tanımlayarak karmaşık metin arama ve düzenlemesine olanak tanır."
      ],
      "metadata": {
        "id": "pckx4EDBH13x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "6mgnPaPuH6qy"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The quick brown fox jumps over the lazy dog.\"\n"
      ],
      "metadata": {
        "id": "vjJGTmpOH8J1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = r'fox'\n",
        "pattern"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7gQJwLJXIBpF",
        "outputId": "fc557169-d1a0-49b4-a121-15294de27b3b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fox'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "match1 = re.search(pattern, text)\n",
        "match1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcdaOYAQIIFy",
        "outputId": "bce03a18-567b-474e-afa3-f27073d6d487"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(16, 19), match='fox'>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if match1:\n",
        "    print(\"Match found:\", match1.group())\n",
        "else:\n",
        "    print(\"No match found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijod0uswIR1d",
        "outputId": "7eed8018-b379-42cc-b66c-d3bb48d56f80"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Match found: fox\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3.2 Yaygın Regex Desenleri ve Sözdizimi**"
      ],
      "metadata": {
        "id": "0Xuy1Sb-J65c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Nokta (.)**"
      ],
      "metadata": {
        "id": "qrAWSn0MMGSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Açıklama: Yeni satır karakteri hariç, herhangi bir tek karakterle eşleşir."
      ],
      "metadata": {
        "id": "0B60kO56MKKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "pattern = r'c.t'  # 'c' ile başlayıp, herhangi bir karakter ve 't' ile biten diziler\n",
        "text = \"catar cot cut bit\"\n",
        "matches = re.findall(pattern, text)\n",
        "print(matches)  # Çıktı: ['cat', 'cot', 'cut']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze98efshMH-9",
        "outputId": "57ff1131-bf59-4ca4-db70-7cb8be6d57ab"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cat', 'cot', 'cut']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Şapka (^)**"
      ],
      "metadata": {
        "id": "f-aq-xbZMwhw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Açıklama: Desenin, metnin başında yer aldığını belirtir."
      ],
      "metadata": {
        "id": "lURyqNA6Mzs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "pattern = r'^Hello'\n",
        "text = \"Hello world, Hello Python\"\n",
        "match = re.search(pattern, text)\n",
        "if match:\n",
        "    print(\"Başlangıçta 'Hello' var.\")  # Çıktı: Başlangıçta 'Hello' var."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia_4G3mAMyG5",
        "outputId": "c27dd9fd-7d94-40a8-c302-1b43e3ff78c8"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Başlangıçta 'Hello' var.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Dolar İşareti ($)**"
      ],
      "metadata": {
        "id": "lRSGwVCwM6lS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Açıklama: Desenin, metnin sonunda yer aldığını belirtir."
      ],
      "metadata": {
        "id": "o_1qAGetM7aJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "pattern = r'Python$'\n",
        "text = \"Welcome to Python\"\n",
        "match = re.search(pattern, text)\n",
        "if match:\n",
        "    print(\"Metin 'Python' ile bitiyor.\")  # Çıktı: Metin 'Python' ile bitiyor."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "empyoyqXM-sP",
        "outputId": "f8759b3b-292d-4db4-cec6-9c38a021f44b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metin 'Python' ile bitiyor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **4. Yıldız (*)**"
      ],
      "metadata": {
        "id": "oDaOJ5ulNHJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Açıklama: Önceki karakterin sıfır veya daha fazla tekrarını eşleştirir."
      ],
      "metadata": {
        "id": "hYNQGYXENMPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "pattern = r'ab*'  # 'a' ile başlayıp, ardından sıfır veya daha fazla 'b'\n",
        "text = \"a ab abb abbb kkkbb abb baaabb\"\n",
        "matches = re.findall(pattern, text)\n",
        "print(matches)  # Çıktı: ['a', 'ab', 'abb', 'abbb']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVPukB68NOXC",
        "outputId": "b1a0fcc8-ddd8-4b74-db0f-a0fa640c53f3"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'ab', 'abb', 'abbb', 'abb', 'a', 'a', 'abb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Artı (+)**"
      ],
      "metadata": {
        "id": "8F_uYOPLNkuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Açıklama: Önceki karakterin bir veya daha fazla tekrarını eşleştirir."
      ],
      "metadata": {
        "id": "stz-fe79NnFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "pattern = r'ab+'  # 'a' ile başlayıp, ardından en az bir 'b'\n",
        "text = \"a ab abb abbb aabb aaa\"\n",
        "matches = re.findall(pattern, text)\n",
        "print(matches)  # Çıktı: ['ab', 'abb', 'abbb']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3gjm617NolR",
        "outputId": "f882e247-5401-4183-f365-ab2db7e99b4e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ab', 'abb', 'abbb', 'abb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Soru İşareti (?)**"
      ],
      "metadata": {
        "id": "TCr8BUTdNySn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Açıklama: Önceki karakterin sıfır veya bir tekrarını eşleştirir; yani karakter opsiyoneldir."
      ],
      "metadata": {
        "id": "COp8T7nGN0s0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "pattern = r'ab?'  # 'a' ile başlayıp, ardından sıfır veya bir 'b'\n",
        "text = \"a ab abb baab\"\n",
        "matches = re.findall(pattern, text)\n",
        "print(matches)  # Çıktı: ['a', 'ab', 'ab']  # İlk 'abb' içinde yalnızca 'ab' eşleşir çünkü 'b' sadece bir kez kabul edilir\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srtofM7LN2J6",
        "outputId": "93bbb5f9-6ab0-44fc-9e36-b3fe3e3ec1fb"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'ab', 'ab', 'a', 'ab']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Köşeli Parantezler ([])**"
      ],
      "metadata": {
        "id": "NZXcyoClOACK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Açıklama: Köşeli parantezler içerisinde belirtilen karakter setlerinden herhangi biriyle eşleşir."
      ],
      "metadata": {
        "id": "fAa0w9fqOCOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "pattern = r'[abc]'  # a, b veya c karakterlerinden herhangi biri\n",
        "text = \"def cab babad\"\n",
        "matches = re.findall(pattern, text)\n",
        "print(matches)  # Çıktı: ['c', 'a', 'b']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GZfgrGmODj9",
        "outputId": "e4dfcd66-4cf9-4ae4-e72e-27485ac95fe7"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['c', 'a', 'b', 'b', 'a', 'b', 'a']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. \\d**"
      ],
      "metadata": {
        "id": "xb32FCehOL7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Açıklama: Bir basamak (digit) ile eşleşir; [0-9] aralığındaki herhangi bir rakam."
      ],
      "metadata": {
        "id": "Gq3Omtg8OObG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "pattern = r'\\d+'  # Bir veya daha fazla rakam\n",
        "text = \"There are 12 apples and 30 oranges. 221 33\"\n",
        "matches = re.findall(pattern, text)\n",
        "print(matches)  # Çıktı: ['12', '30']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q5ywHM4OQYw",
        "outputId": "91259e46-abe6-4278-e71d-94e95c817ef2"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['12', '30', '221', '33']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. \\w**"
      ],
      "metadata": {
        "id": "1K66-MEGOZKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Açıklama: Herhangi bir alfasayısal karakter (harf, rakam, alt çizgi) ile eşleşir; [a-zA-Z0-9_] ile aynı anlama gelir."
      ],
      "metadata": {
        "id": "YTd3_yGjObsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "pattern = r'\\w+'  # Bir veya daha fazla alfasayısal karakter\n",
        "text = \"Hello_world 123! smile_x world , a , __,.\"\n",
        "matches = re.findall(pattern, text)\n",
        "print(matches)  # Çıktı: ['Hello_world', '123']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waAc1eVCOeLK",
        "outputId": "659c41cf-17ee-4ed4-b44e-70d08826d6d6"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello_world', '123', 'smile_x', 'world', 'a', '__']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. \\s**"
      ],
      "metadata": {
        "id": "18d3LdC-O1Ej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Açıklama: Bir boşluk karakteri ile eşleşir; boşluk, sekme, yeni satır gibi karakterleri kapsar."
      ],
      "metadata": {
        "id": "DO0CLYERO3P2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "pattern = r'\\s+'  # Bir veya daha fazla boşluk karakteri\n",
        "text = \"Hello   world\\tPython //m\"\n",
        "matches = re.findall(pattern, text)\n",
        "print(matches)  # Çıktı: ['   ', '\\t']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyxVgObKO6OE",
        "outputId": "c5aab639-3bd4-4c62-a246-a0eb284a8e69"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['   ', '\\t', ' ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Dikey Çizgi (|)**"
      ],
      "metadata": {
        "id": "MgesGk3zPCkq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Açıklama: Alternatif (veya) operatörüdür; bir desen veya diğer desenle eşleşir."
      ],
      "metadata": {
        "id": "gf7U6ECTPFAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "pattern = r'cat|dog'  # \"cat\" veya \"dog\" kelimelerinden herhangi biri\n",
        "text = \"I have a cat and a dog. cat and dogs\"\n",
        "matches = re.findall(pattern, text)\n",
        "print(matches)  # Çıktı: ['cat', 'dog']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGybVxCcPGWN",
        "outputId": "01d38f75-4736-45a5-9970-9e5047b0316c"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cat', 'dog', 'cat', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. Parantezler (())**"
      ],
      "metadata": {
        "id": "IyS3YzoKPL40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "pattern = r'(\\d+)-(\\d+)-(\\d+)'  # İki grup halinde rakamları yakalar, aralarında tire bulunan desen\n",
        "text = \"The serial number is 1232342-234-456344.\"\n",
        "match = re.search(pattern, text)\n",
        "if match:\n",
        "    print(\"Birinci grup:\", match.group(1))  # Çıktı: Birinci grup: 123\n",
        "    print(\"İkinci grup:\", match.group(2))   # Çıktı: İkinci grup: 456\n",
        "    print(\"üçüncü grup:\", match.group(3))   # Çıktı: İkinci grup: 456\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLngXy6lPOir",
        "outputId": "c69fa490-41a4-4b44-d7a0-fb7c05600a1b"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Birinci grup: 1232342\n",
            "İkinci grup: 234\n",
            "üçüncü grup: 456344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mail Adreslerini ayıkla**"
      ],
      "metadata": {
        "id": "Wl0XTf1tQSbH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Özetle, bu desen e-posta adreslerinde genellikle görülen formatı yakalamayı amaçlar:\n",
        "\n",
        "[geçerli karakterler]@[geçerli karakterler].[geçerli uzantı]"
      ],
      "metadata": {
        "id": "13BCk4mCQVxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# Sample text with email addresses\n",
        "text = \"Please contact us at support@example.com or sales@example.com for further information.\"\n",
        "# Correct regex pattern to match email addresses\n",
        "pattern = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b\"\n",
        "# Use re.findall() to find all matches\n",
        "emails = re.findall(pattern, text)\n",
        "# Display the extracted email addresses\n",
        "print(\"Extracted Email Addresses:\")\n",
        "print(emails)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPfV4wGRPtho",
        "outputId": "00e81d99-dea1-4b86-8595-06c38b89b258"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Email Addresses:\n",
            "['support@example.com', 'sales@example.com']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Telefon numaralarını ayıkla**"
      ],
      "metadata": {
        "id": "saZxcIP9Qjy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desenin Açıklaması:\n",
        "\n",
        "\\( ve \\): Parantez karakterlerini (yani \"(\" ve \")\") aramak için kullanılır.\n",
        "\n",
        "\\d{3}: Üç basamaktan oluşan bir sayı dizisini temsil eder.\n",
        "\n",
        "(boşluk): Parantez kapandıktan sonra gelen boşluk karakterini eşleştirir.\n",
        "\n",
        "\\d{3}: Üç basamaklı ikinci sayı dizisini eşleştirir.\n",
        "\n",
        "-: Tire (-) karakterini eşleştirir.\n",
        "\n",
        "\\d{4}: Son dört basamaklı sayı dizisini eşleştirir.\n",
        "\n",
        "Bu şekilde kodu çalıştırdığınızda, beklenen telefon numarası listesini almanız gerekir."
      ],
      "metadata": {
        "id": "W-EQh__EQ0LV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# Sample text with phone numbers\n",
        "text = \"Contact us at (123) 456-7890 or (987) 654-3210.\"\n",
        "# Correct regex pattern to match phone numbers\n",
        "pattern = r\"\\(\\d{3}\\) \\d{3}-\\d{4}\"\n",
        "# Use re.findall() to find all matches\n",
        "phone_numbers = re.findall(pattern, text)\n",
        "# Display the extracted phone numbers\n",
        "print(\"Extracted Phone Numbers:\")\n",
        "print(phone_numbers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW2L8-2BQopL",
        "outputId": "6e93a762-e638-4f43-fafe-8bcebd9d669a"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Phone Numbers:\n",
            "['(123) 456-7890', '(987) 654-3210']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Alt dizeleri değiştirme**"
      ],
      "metadata": {
        "id": "ghvR1E9iQ_10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# Sample text\n",
        "text = \"The quick brown FOX jumps over the lazy dog. The fox is clever.\"\n",
        "# Define a pattern to match the word \"fox\"\n",
        "pattern = r\"FOX\"\n",
        "# Use re.sub() to replace \"fox\" with \"cat\"\n",
        "new_text = re.sub(pattern, \"XXX\", text)\n",
        "# Display the modified text\n",
        "print(\"Modified Text:\")\n",
        "print(new_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edTVYg8SRE7s",
        "outputId": "d2f4f178-920b-43af-c8fd-3aa76edb8d15"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modified Text:\n",
            "The quick brown XXX jumps over the lazy dog. The fox is clever.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3.4 Gelişmiş Regex Teknikleri**"
      ],
      "metadata": {
        "id": "zjKZiKEoRWYI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tarihleri ​​Çıkarma**"
      ],
      "metadata": {
        "id": "MKZzYMyfRaF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# Sample text with dates\n",
        "text = \"The event is scheduled for 2022-08-15. Another event is on 15/08/2022.\"\n",
        "# Correct regex pattern to match dates\n",
        "pattern = r\"\\b(?:\\d{4}-\\d{2}-\\d{2}|\\d{2}/\\d{2}/\\d{4})\\b\"\n",
        "# Use re.findall() to find all matches\n",
        "dates = re.findall(pattern, text)\n",
        "# Display the extracted dates\n",
        "print(\"Extracted Dates:\")\n",
        "print(dates)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7OPk-5-RdsQ",
        "outputId": "13d2b096-d4ec-4388-e6fa-cac8ceffd1e4"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Dates:\n",
            "['2022-08-15', '15/08/2022']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desenin Açıklaması:\n",
        "\n",
        "\\b\n",
        "\n",
        "Kelime sınırını belirtir; tarih ifadesinin tam bir kelime olarak eşleşmesini sağlar.\n",
        "\n",
        "(?: ... )\n",
        "\n",
        "Non-capturing group: Parantez içindeki desen gruplamasını yapar, ancak yakalanan grup sonuçlara dahil edilmez.\n",
        "\n",
        "\\d{4}-\\d{2}-\\d{2}\n",
        "\n",
        "YYYY-AA-GG formatındaki tarihi yakalar.\n",
        "\n",
        "\\d{4}: 4 basamaklı yıl\n",
        "\n",
        "-: Tire karakteri\n",
        "\n",
        "\\d{2}: 2 basamaklı ay\n",
        "\n",
        "-: Tire karakteri\n",
        "\n",
        "\\d{2}: 2 basamaklı gün\n",
        "\n",
        "\\d{2}/\\d{2}/\\d{4}\n",
        "\n",
        "DD/AA/YYYY formatındaki tarihi yakalar.\n",
        "\n",
        "\n",
        "\\d{2}: 2 basamaklı gün\n",
        "\n",
        "/: Slash karakteri\n",
        "\n",
        "\\d{2}: 2 basamaklı ay\n",
        "\n",
        "/: Slash karakteri\n",
        "\n",
        "\\d{4}: 4 basamaklı yıl\n",
        "|\n",
        "Alternatif operatör; iki farklı tarih formatından birine eşleşmeyi sağlar.\n",
        "\n",
        "Bu şekilde kodu çalıştırdığınızda, metindeki her iki tarih formatı da doğru şekilde yakalanacaktır."
      ],
      "metadata": {
        "id": "nevNlAzvRr62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Tokenleştirme"
      ],
      "metadata": {
        "id": "mtVaDX_sSDmJ"
      }
    }
  ]
}